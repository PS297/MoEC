{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "498b3eee-654c-433e-9075-a7ae553e8cd2",
   "metadata": {},
   "source": [
    "## Importing Necessary Libaray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29b76fb8-6e5b-454e-abf4-3cf68cdc94ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pymoo.algorithms.moo.nsga3 import NSGA3\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.operators.sampling.rnd import FloatRandomSampling\n",
    "from pymoo.operators.crossover.sbx import SimulatedBinaryCrossover\n",
    "from pymoo.operators.mutation.pm import PolynomialMutation\n",
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix, f1_score, roc_auc_score, roc_curve, auc, precision_score, recall_score\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.util.normalization import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pymoo.util.ref_dirs import get_reference_directions\n",
    "from pymoo.core.callback import Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b1c781-56f6-4db4-8556-cec1f2cbf3fa",
   "metadata": {},
   "source": [
    "## Loading Haberman Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f684f94-8b2f-4fbb-861f-4acaa353ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()   ## Standarizing Function\n",
    "df_Hab = pd.read_csv(\"Haberman.csv\") ## Reading Haberman Dataset\n",
    "data = df_Hab\n",
    "\n",
    "df_Hab.replace('?', np.nan, inplace=True) ## Replace '?' with NaN\n",
    "df_Hab = df_Hab.apply(pd.to_numeric, errors='coerce') ## Convert columns to numeric, forcing errors to NaN\n",
    "means = df_Hab.mean() ## Calculate mean of each column (ignoring NaNs)\n",
    "df_Hab.fillna(means, inplace=True) ## Replacing NaN values with the corresponding mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096b80c2-d260-4bda-953e-daa9eef83f75",
   "metadata": {},
   "source": [
    "## Extracting Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ce5e105-b29c-4888-b7ca-911cc4b9f537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306 3 (306,)\n"
     ]
    }
   ],
   "source": [
    "X_Hab = df_Hab.iloc[: , 0:3].values\n",
    "X_Hab = scaler.fit_transform(X_Hab)  ## Standaarizing the data\n",
    "\n",
    "y_Hab = data['Label'].map({1:0, 2:1}).values\n",
    "Num_Samples , Num_Features = X_Hab.shape\n",
    "Num_Classes = df_Hab['Label'].nunique()\n",
    "print(Num_Samples , Num_Features , y_Hab.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72908d96-150a-42c9-a9d9-b55f84e68f66",
   "metadata": {},
   "source": [
    "## Segregating Data into Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae355966-6da1-4deb-9102-4470b276bd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: (214, 3) , Train dataset label size: (214,)\n",
      "Test dataset size: (92, 3) , Test dataset label size: (92,)\n"
     ]
    }
   ],
   "source": [
    "X_train_Hab , X_test_Hab , y_train_Hab , y_test_Hab = train_test_split(X_Hab , y_Hab , test_size = 0.3 , random_state = 42)\n",
    "\n",
    "print(f\"Train dataset size: {X_train_Hab.shape} , Train dataset label size: {y_train_Hab.shape}\")\n",
    "print(f\"Test dataset size: {X_test_Hab.shape} , Test dataset label size: {y_test_Hab.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09335f7e-cad6-49fd-ae98-57fde7e01a71",
   "metadata": {},
   "source": [
    "## Defining Logistic Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0df94b5-93d8-4824-845e-34414e5fc55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticFunctionModule:\n",
    "    def __init__(self, n_features):\n",
    "        self.weights = np.zeros(n_features + 1)  ## Initializing weights and bias term\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def predict(self, X):\n",
    "        z = np.dot(X, self.weights[1:]) + self.weights[0]\n",
    "        return self.sigmoid(z)\n",
    "\n",
    "    def compute_loss(self, X, y):\n",
    "        m = len(y)\n",
    "        predictions = self.predict(X)\n",
    "        loss = - (1/m) * (np.dot(y, np.log(predictions + 1e-15)) + np.dot(1 - y, np.log(1 - predictions + 1e-15)))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ca433-1999-46db-ad23-1d0f4cf5b29a",
   "metadata": {},
   "source": [
    "## Defining Many-Objective Function Including Model's Loss and Feature Importance of All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef047fca-fe26-44cb-bc4d-df5fcc66c31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiObjectiveExplainableProblem(ElementwiseProblem):\n",
    "    def __init__(self , X_train , y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        super().__init__(n_var = X_train.shape[1] + 1,  ## Number of learnable varaibales (weights and bias parameters)\n",
    "                         n_obj = X_train.shape[1] + 1,  \n",
    "                         n_constr = 0,\n",
    "                         xl = -1,  \n",
    "                         xu = 1)   \n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def predict(self, X):\n",
    "        z = np.dot(X, self.weights[1:]) + self.weights[0]\n",
    "        return self.sigmoid(z)\n",
    "\n",
    "    def compute_loss(self, X, y):\n",
    "        m = len(y)\n",
    "        predictions = self.predict(X)\n",
    "        loss = - (1/m) * (np.dot(y, np.log(predictions + 1e-15)) + np.dot(1 - y, np.log(1 - predictions + 1e-15)))\n",
    "        return loss\n",
    "\n",
    "    def compute_metrics(self , X , y):\n",
    "        predictions = self.predict(X) >= 0.5\n",
    "        accuracy = accuracy_score(y , predictions)\n",
    "        precision = precision_score(y , predictions)\n",
    "        recall = recall_score(y , predictions)\n",
    "        f1_val = f1_score(y , predictions)\n",
    "        tn , fp , fn , tp = confusion_matrix(y , predictions).ravel()\n",
    "        specificity = tn / (tn+fp)\n",
    "        return accuracy , precision , recall , specificity , f1_val\n",
    "        \n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        \n",
    "        self.weights = x\n",
    "        \n",
    "        loss = self.compute_loss(self.X_train , self.y_train)\n",
    "\n",
    "        explainer = shap.Explainer(self.predict, self.X_train)\n",
    "        shap_values = explainer(self.X_train)\n",
    "\n",
    "        mean_shap_values = np.mean(shap_values.values , axis = 0 ) \n",
    "\n",
    "        objectives = np.array([loss] + [-v for v in mean_shap_values])\n",
    "        \n",
    "        out[\"F\"] = objectives\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98972cb6-6736-43f0-a878-74db3b841ecd",
   "metadata": {},
   "source": [
    "## Implementing MoEC Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81609c1e-34f5-4375-9662-2f32d678c1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reference directions: 100\n",
      "==========================================================\n",
      "n_gen  |  n_eval  | n_nds  |      eps      |   indicator  \n",
      "==========================================================\n",
      "     1 |      100 |     26 |             - |             -\n",
      "     2 |      130 |     33 |  0.0164984633 |         ideal\n",
      "     3 |      160 |     31 |  0.0135589852 |         ideal\n",
      "     4 |      190 |     33 |  0.0154017013 |         nadir\n",
      "     5 |      220 |     36 |  0.0117273373 |         ideal\n",
      "     6 |      250 |     38 |  0.0180907823 |         ideal\n",
      "     7 |      280 |     44 |  0.3862799832 |         nadir\n",
      "     8 |      310 |     45 |  0.0421894889 |         ideal\n",
      "     9 |      340 |     41 |  0.1157821693 |         nadir\n",
      "    10 |      370 |     40 |  0.0178322881 |             f\n"
     ]
    }
   ],
   "source": [
    "Num_Obj = X_train_Hab.shape[1] + 1\n",
    "Ref_Dirs = get_reference_directions(\"energy\", Num_Obj, n_points=100)\n",
    "print(f\"Number of reference directions: {len(Ref_Dirs)}\") ## Number of reference directions generated\n",
    "\n",
    "\n",
    "algorithm = NSGA3(\n",
    "    pop_size = len(Ref_Dirs),  # Set population size equal to reference directions\n",
    "    ref_dirs = Ref_Dirs,\n",
    "    n_offsprings = 30,\n",
    "    sampling = FloatRandomSampling(),\n",
    "    crossover = SimulatedBinaryCrossover(prob = 0.9 , eta = 15),\n",
    "    mutation = PolynomialMutation(eta = 20),\n",
    "    eliminate_duplicates = True\n",
    ")\n",
    "\n",
    "problem = MultiObjectiveExplainableProblem(X_train_Hab, y_train_Hab)\n",
    "\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               termination = ('n_gen', 10),\n",
    "               seed = 1,\n",
    "               verbose = True,\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d33543-2a54-4c79-aef4-4d68234e1555",
   "metadata": {},
   "source": [
    "## Computing Quantitaive Metrics for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1773a92-2e03-46e7-ad93-524c99f41339",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting the best solution\n",
    "for i in range(len(res.F)):\n",
    "    \n",
    "    best_solution = res.X[i]\n",
    "    \n",
    "    model = LogisticFunctionModule(n_features = X_train_Hab.shape[1])\n",
    "    model.weights = best_solution \n",
    "    \n",
    "    def evaluate_model(model, X, y):\n",
    "        probabilities = model.predict(X)\n",
    "        predictions = model.predict(X) >= 0.5\n",
    "        accuracy = np.mean(predictions == y)\n",
    "        sensitivity = np.sum((predictions == 1) & (y == 1)) / np.sum(y == 1)\n",
    "        specificity = np.sum((predictions == 0) & (y == 0)) / np.sum(y == 0)\n",
    "        f1_val = 2 * (sensitivity * np.sum((predictions == 1) & (y == 1)) / np.sum(predictions == 1)) / (sensitivity + np.sum((predictions == 1) & (y == 1)) / np.sum(predictions == 1))\n",
    "        precision = precision_score(y , predictions)\n",
    "        auc = roc_auc_score(y, probabilities)\n",
    "        return accuracy, sensitivity, specificity, f1_val, precision, auc\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    accuracy, sensitivity, specificity, f1_score, precision, auc = evaluate_model(model, X_test_Hab, y_test_Hab)\n",
    "    print(f\"Soluion for :{i}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Test Sensitivity: {sensitivity:.4f}\")\n",
    "    print(f\"Test Specificity: {specificity:.4f}\")\n",
    "    print(f\"Test F1 Score: {f1_score:.4f}\")\n",
    "    print(f\"Test Precision Score: {precision:.4f}\")\n",
    "    print(f\"Test AUC Score: {auc:.4f}\")\n",
    "    print(\"-----------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a36e22-3f3a-4938-a4b1-424b692531dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
